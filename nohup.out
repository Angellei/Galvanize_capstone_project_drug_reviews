/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.
  'stop_words.' % sorted(inconsistent))
Traceback (most recent call last):
  File "AWS_test_building_model.py", line 50, in <module>
    X_train = con_vec.fit_transform(df['review'])
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py", line 1613, in fit_transform
    X = super(TfidfVectorizer, self).fit_transform(raw_documents)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py", line 1031, in fit_transform
    self.fixed_vocabulary_)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py", line 943, in _count_vocab
    for feature in analyze(doc):
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py", line 329, in <lambda>
    tokenize(preprocess(self.decode(doc))), stop_words)
  File "AWS_test_building_model.py", line 29, in tokenize
    tokens = nltk.word_tokenize(text)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py", line 128, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/tokenize/__init__.py", line 95, in sent_tokenize
    return tokenizer.tokenize(text)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1241, in tokenize
    return list(self.sentences_from_text(text, realign_boundaries))
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1291, in sentences_from_text
    return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1291, in <listcomp>
    return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1281, in span_tokenize
    for sl in slices:
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1322, in _realign_boundaries
    for sl1, sl2 in _pair_iter(slices):
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 313, in _pair_iter
    prev = next(it)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nltk/tokenize/punkt.py", line 1295, in _slices_from_text
    for match in self._lang_vars.period_context_re().finditer(text):
KeyboardInterrupt
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.
  'stop_words.' % sorted(inconsistent))
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.
  'stop_words.' % sorted(inconsistent))
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.
  'stop_words.' % sorted(inconsistent))
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.
  'stop_words.' % sorted(inconsistent))
[I 22:26:41.088 NotebookApp] Using EnvironmentKernelSpecManager...
[I 22:26:41.088 NotebookApp] Started periodic updates of the kernel list (every 3 minutes).
[W 22:26:41.228 NotebookApp] All authentication is disabled.  Anyone who can connect to this server will be able to run code.
[I 22:26:41.241 NotebookApp] Loading IPython parallel extension
[I 22:26:41.261 NotebookApp] JupyterLab beta preview extension loaded from /home/ubuntu/anaconda3/lib/python3.6/site-packages/jupyterlab
[I 22:26:41.261 NotebookApp] JupyterLab application directory is /home/ubuntu/anaconda3/share/jupyter/lab
[I 22:26:41.387 NotebookApp] [nb_conda] enabled
[I 22:26:41.388 NotebookApp] Serving notebooks from local directory: /home/ubuntu/Galvanize_capstone_project_drug_reviews
[I 22:26:41.388 NotebookApp] 0 active kernels
[I 22:26:41.388 NotebookApp] The Jupyter Notebook is running at:
[I 22:26:41.388 NotebookApp] http://localhost:48889/
[I 22:26:41.388 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 22:26:41.389 NotebookApp] Starting initial scan of virtual environments...
[I 22:26:42.998 NotebookApp] Found new kernels in environments: conda_theano_p36, conda_theano_p27, conda_caffe_p35, conda_caffe2_p27, conda_cntk_p36, conda_amazonei_mxnet_p27, conda_tensorflow_p27, conda_python2, conda_chainer_p27, conda_mxnet_p36, conda_python3, conda_pytorch_p27, conda_amazonei_tensorflow_p27, conda_caffe_p27, conda_mxnet_p27, conda_cntk_p27, conda_amazonei_mxnet_p36, conda_pytorch_p36, conda_chainer_p36, conda_tensorflow_p36, conda_amazonei_tensorflow_p36, conda_anaconda3
[C 01:37:02.885 NotebookApp] received signal 15, stopping
[I 01:37:04.486 NotebookApp] Shutting down 0 kernels
