{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "#import requests\n",
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "## remove special symbol\n",
    "def rm_sym(df):\n",
    "    df['review'] = df['review'].str.replace(\"&#039;\",'\\'')\n",
    "    df['review'].head()\n",
    "    df['rating_cate'] = ''\n",
    "    df.loc[df['rating'] >= 7,'rating_cate'] = 'high'\n",
    "    df.loc[df['rating'] <= 4,'rating_cate'] = 'low'\n",
    "    df.loc[(df['rating'] > 4) & (df['rating'] < 7),'rating_cate'] = 'medium'\n",
    "    return df\n",
    "\n",
    "def clean_text(df_tem3):\n",
    "    df_tem3['review'] = df_tem3['review'].str.replace(\"\\\"\",\"\").str.lower()\n",
    "    df_tem3['review'] = df_tem3['review'].str.replace( r\"(\\\\r)|(\\\\n)|(\\\\t)|(\\\\f)|(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(&#039;)|(\\d\\s)|(\\d)|(\\/)\",\"\")\n",
    "    df_tem3['review'] = df_tem3['review'].str.replace(\"\\\"\",\"\").str.lower()\n",
    "    df_tem3['review'] = df_tem3['review'].str.replace( r\"(\\$)|(\\-)|(\\\\)|(\\s{2,})\",\" \")\n",
    "    df_tem3['review'].sample(1).iloc[0]\n",
    "\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    df_tem3['review'] = df_tem3['review'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split(\" \")]))\n",
    "    return df_tem3\n",
    "\n",
    "\n",
    "np.random.seed(9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('drugsCom_raw/drugsComTrain_raw.tsv',sep='\\t',index_col=0)#.sample(40000)\n",
    "df = rm_sym(df)\n",
    "df_tem3 = df\n",
    "\n",
    "test = pd.read_csv(\"drugsCom_raw/drugsComTest_raw.tsv\",sep='\\t', index_col=0)\n",
    "test = rm_sym(test)\n",
    "\n",
    "df_tem3 = clean_text(df_tem3)\n",
    "test = clean_text(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_cate\n",
       "high      106866\n",
       "low        40075\n",
       "medium     14356\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tem3.groupby('rating_cate').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161297, 7)\n",
      "(53766, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_tem3.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow \n",
    "\n",
    "#from tensorflow import tensorflow.keras\n",
    "\n",
    "#from keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPool1D \n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "MAX_NB_WORDS = 500\n",
    "max_review_length = 500\n",
    "EMBEDDING_DIM = 160\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words = MAX_NB_WORDS, \n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "                      lower=True, split=' ', char_level=False, \n",
    "                      oov_token=None, document_count=0)\n",
    "\n",
    "tokenizer.fit_on_texts(df_tem3['review'])\n",
    "train_sequences = tokenizer.texts_to_sequences(df_tem3['review'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate and pad input sequences\n",
    "X_train = sequence.pad_sequences(train_sequences, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(test_sequences, maxlen = max_review_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206461</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95260</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92703</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138000</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35696</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        high  low  medium\n",
       "206461     1    0       0\n",
       "95260      1    0       0\n",
       "92703      0    0       1\n",
       "138000     1    0       0\n",
       "35696      1    0       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform y to get_dummies\n",
    "y_train = pd.get_dummies(df_tem3['rating_cate'])\n",
    "y_test = pd.get_dummies(test['rating_cate'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161297, 500) <-- shape of train_data ready for val/train split.\n",
      "(53766, 500) <-- shape of final_test_data ready for fedding to network.\n",
      "52265 <-- Length of Word Index\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of data. \n",
    "\n",
    "print(X_train.shape, '<-- shape of train_data ready for val/train split.')\n",
    "print(X_test.shape, '<-- shape of final_test_data ready for fedding to network.')\n",
    "print(len(tokenizer.word_index), '<-- Length of Word Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train and validation data by dividing train_data in 80:20 ratio\n",
      "train data shape: (129037, 500)\n",
      "validation data shape: (32260, 500)\n",
      "Data is ready for training!!\n"
     ]
    }
   ],
   "source": [
    "# Split Training & Validation Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "print('creating train and validation data by dividing train_data in 80:20 ratio')\n",
    "######################################################\n",
    "\n",
    "X_train_t, X_train_val, Y_train_t, y_train_val = train_test_split(X_train, y_train,test_size = 0.2)\n",
    "\n",
    "######################################################\n",
    "print('train data shape:', X_train_t.shape)\n",
    "print('validation data shape:', X_train_val.shape)\n",
    "print('Data is ready for training!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up Model Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words  = min(MAX_NB_WORDS, len(word_index))\n",
    "lstm_out = max_review_length\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words,EMBEDDING_DIM,input_length=max_review_length))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "## add conv using kernal No.32 and size 3x3, actiation='relu'(rm neg)\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "#model.add(Attention(max_review_length))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "## one-code mutiple categories targets use 'categorical_crossentropy' not 'binary_crossentropy'\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 160)          80000     \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 500, 40)           28960     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 40)                9760      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 123       \n",
      "=================================================================\n",
      "Total params: 118,843\n",
      "Trainable params: 118,843\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug_Data_LSTM_w_stopwords_1.0_trainging_cycle1batchsize_32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 129037 samples, validate on 32260 samples\n",
      "Epoch 1/40\n",
      "129037/129037 [==============================] - 3207s 25ms/step - loss: 0.6111 - acc: 0.7655 - val_loss: 0.5749 - val_acc: 0.7801\n",
      "Epoch 2/40\n",
      "129037/129037 [==============================] - 3199s 25ms/step - loss: 0.5307 - acc: 0.7988 - val_loss: 0.5070 - val_acc: 0.8073\n",
      "Epoch 3/40\n",
      " 58176/129037 [============>.................] - ETA: 27:38 - loss: 0.5014 - acc: 0.8078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129037/129037 [==============================] - 3194s 25ms/step - loss: 0.4798 - acc: 0.8162 - val_loss: 0.4889 - val_acc: 0.8140\n",
      "Epoch 5/40\n",
      " 92928/129037 [====================>.........] - ETA: 14:04 - loss: 0.4609 - acc: 0.8232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129037/129037 [==============================] - 3195s 25ms/step - loss: 0.4427 - acc: 0.8307 - val_loss: 0.4758 - val_acc: 0.8198\n",
      "Epoch 7/40\n",
<<<<<<< HEAD
      " 76864/129037 [================>.............] - ETA: 20:21 - loss: 0.4233 - acc: 0.8376"
=======
      " 59744/129037 [============>.................] - ETA: 38:10 - loss: 0.3743 - acc: 0.8568"
>>>>>>> 59683afe17a2fbc5f4ca4ab8f5ff3b0793b5baa1
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Run LSTM Model\n",
    "batch = 32 \n",
    "epoch = 40\n",
    "\n",
    "## set name for the mdoel\n",
    "training_cycle = 1\n",
    "notebookname = \"Drug_Data_\"\n",
    "variant = \"LSTM_w_stopwords_\"\n",
    "version = \"1.0_\"\n",
    "title = notebookname + variant + version\n",
    "\n",
    "stamp = '{}trainging_cycle{}batchsize_{}'.format(title,training_cycle,batch)\n",
    "print(stamp)\n",
    "\n",
    "## save the best model\n",
    "best_model_path = title + stamp + 'best.h5'\n",
    "model_checkpoint = ModelCheckpoint(best_model_path, save_best_only = True) ## save only best model\n",
    "\n",
    "## if 4 steps without decreasing of loss in valid set, stop the trainning\n",
    "early_stopping = EarlyStopping(patience = 4)\n",
    "\n",
    "LSTM_model = model.fit(X_train_t, Y_train_t, batch_size=batch, epochs=epoch,\n",
    "                       validation_data=(X_train_val, y_train_val),callbacks=[early_stopping], shuffle = True)\n",
    "\n",
    "best_score = min(LSTM_model.history['val_loss'])\n",
    "\n",
    "## why difference between train and val loss could be randomly different? local optima?\n",
    "## add dropout to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_history = pd.DataFrame(LSTM_model.history)\n",
    "file_name = str(LSTM_model.params['samples']) + \"_20_bilstm_2layer.csv\"\n",
    "LSTM_model_history.to_csv('./model_report/0403/' + file_name)\n",
    "model.save('./model_report/0403/129037_20_bilstm_2layer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epoch')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4VdW9//H3NzMJYQgZSYAwigwiEEGgDjgw1AGtOKGIbdXaaq39tb3V/m5/9dF7297b1mtva20dCyp1wKEiKlAVxApIQMYwzwlJyAABEjKe9fvjHGyMkQQ4JzvD5/U858nZ+6y9z/c8gfPJ3mvvtcw5h4iIyMmEeV2AiIi0fgoLERFpksJCRESapLAQEZEmKSxERKRJCgsREWmSwkJERJqksBARkSYpLEREpEkRXhcQLImJiS4zM9PrMkRE2pTVq1cXO+eSmmrXbsIiMzOT7Oxsr8sQEWlTzGxvc9rpNJSIiDRJYSEiIk1SWIiISJMUFiIi0iSFhYiINElhISIiTVJYiIhIkzp8WJRV1PDo4m1sLzzqdSkiIq1Whw+LOuf489Kd/PWTPV6XIiLSanX4sEiIi2LaiJ68viaPsuM1XpcjItIqdfiwAJg1PpPjNXXMW53rdSkiIq2SwgIYlt6V0X268/zyPfh8zutyRERaHYVFwG3j+rCnpIKPthd5XYqISKujsAiYOiyNpPhoZqujW0TkSxQWAVERYcwY05sl24rYU1zudTkiIq2KwqKeGWN7E27GCyuaNby7iEiHobCoJ6VLDFOGpfJK9n4qqmu9LkdEpNVQWDRw+/hMjlTW8uZnB7wuRUSk1VBYNDC6T3eGpHVhzvI9OKfLaEVEQGHxJWbGrPF92FJwlJW7S70uR0SkVVBYNGLauel0i41kzvI9XpciItIqKCwaERMZzo1ZvVi4qZD8suNelyMi4rmQhoWZTTGzrWa2w8we+Io2N5hZjpltMrO59dbPMrPtgcesUNbZmFvP74PPOV5csa+l31pEpNUJWViYWTjwODAVGALcbGZDGrQZCDwITHDODQXuD6xPAH4BjAXGAL8ws+6hqrUxvRJiuXRwCn/7dB9VtXUt+dYiIq1OKI8sxgA7nHO7nHPVwEvAtAZt7gQed84dAnDOHQysnwwsds6VBl5bDEwJYa2NmjW+DyXl1byzIb+l31pEpFUJZVikA/vrLecG1tU3CBhkZv80sxVmNuUUtsXM7jKzbDPLLioK/gCAXxuQSL+kOP76ie7oFpGOzesO7ghgIHAxcDPwlJl1a+7GzrknnXNZzrmspKSkoBdnZswal8m6/YdZu/9w0PcvItJWhDIs8oBe9ZYzAuvqywXecs7VOOd2A9vwh0dztm0R3xiVTlxUOHM0Gq2IdGChDItVwEAz62tmUcBNwFsN2ryJ/6gCM0vEf1pqF7AQmGRm3QMd25MC61pcfEwk00dn8Pb6fIqPVXlRgoiI50IWFs65WuBe/F/ym4FXnHObzOxhM7s60GwhUGJmOcCHwE+ccyXOuVLgEfyBswp4OLDOEzPHZVJd5+PlVfubbiwi0g5Zexn/KCsry2VnZ4ds/zOfWcmOg8dY9m8TiQj3uqtHRCQ4zGy1cy6rqXb61mum28Zlkl9WyeKcQq9LERFpcQqLZrpkcDIZ3Tsxe/ker0sREWlxCotmCg8zZp7fhxW7StlScMTrckREWpTC4hTckNWL6Igw5izXTXoi0rEoLE5B97gopp3bkzfW5FF2vMbrckREWozC4hTdNi6T4zV1vJqty2hFpONQWJyiYeldyerTnedX7MXnax+XHYuINEVhcRpuG5/J3pIKlm4P/uCFIiKtkcLiNEwZmkpyfDSzNV6UiHQQCovTEBURxoyxvVmytYg9xeVelyMiEnIKi9M0Y2xvIsON51foMloRaf8UFqcpOT6GqcPSeCV7P+VVtV6XIyISUgqLMzBrfB+OVtby5lpPptoQEWkxCoszMKp3d4ald2HOJ3tpL6P3iog0RmFxBsyM28ZlsrXwKCt2eTbdhohIyCksztDVI3rSPTaSOcv3eF2KiEjIKCzOUExkODee15tFOYUcOHzc63JEREJCYREEt4ztjXOOF1fqMloRaZ8UFkHQKyGWS89O4W+f7qeyps7rckREgk5hESS3j8+ktLyaBevzvS5FRCToFBZBMr5/DwYkd1ZHt4i0SwqLIDEzZo3rw7rcMtbuP+x1OSIiQaWwCKJrR2XQOTpCo9GKSLujsAiiztERTB+dwYL1+RQdrfK6HBGRoFFYBNnMcX2orvPx8qp9XpciIhI0Cosg65/UmQsGJvLCin3U1Pm8LkdEJCgUFiEwa1wmBUcqWZxT6HUpIiJBobAIgYmDk+mV0Ekd3SLSbigsQiA8zJh5fh9W7i5lc/4Rr8sRETljCosQuSGrFzGRYcxZrvGiRKTtU1iESLfYKK45N503P8ujrKLG63JERM6IwiKEbhuXyfGaOl5dvd/rUkREzojCIoSG9OzCmMwE5izfi8+naVdFpO0KaViY2RQz22pmO8zsgUZev93MisxsbeBxR73X6uqtfyuUdYbSbeP7sK+0giXbDnpdiojIaYsI1Y7NLBx4HLgcyAVWmdlbzrmcBk1fds7d28gujjvnzg1VfS1l8tBUUrpEM/uTvVwyOMXrckRETksojyzGADucc7ucc9XAS8C0EL5fqxQZHsYtY/uwdFsRu4vLvS5HROS0hDIs0oH6Pbu5gXUNXWdm681snpn1qrc+xsyyzWyFmV0Tsiqdg89egMqykL3FTWN6ERlumutCRNosrzu45wOZzrlzgMXA7Hqv9XHOZQEzgMfMrH/Djc3srkCgZBcVFZ1eBcXbYf4P4KVboDY0I8Umx8fw9eFpzMvOpbyqNiTvISISSqEMizyg/pFCRmDd55xzJc65E9/QTwOj672WF/i5C1gCjGz4Bs65J51zWc65rKSkpNOrMmkQTPsT7FkGr98FvtDMoT1rfCZHq2p547O8phuLiLQyoQyLVcBAM+trZlHATcAXrmoys7R6i1cDmwPru5tZdOB5IjABaNgxHjwjboTLH4GcN+Hdn/pPTQXZyF7dGJ7elTnL9+BCsH8RkVAKWVg452qBe4GF+EPgFefcJjN72MyuDjS7z8w2mdk64D7g9sD6s4HswPoPgV83chVVcE24D8bdC6uegmW/DfruzYxZ4zPZVniM5btKgr5/EZFQsvbyV25WVpbLzs4+s534fPDGd2DDK3DV/8LoWcEpLqCypo5xv3qfsX178OeZo5veQEQkxMxsdaB/+KS87uBuXcLCYNrj0P9SePt+2PJOUHcfExnOTWN6syingA+2aK4LEWk7FBYNRUTBDXMg7VyY903YtyKou//exf0Zlt6Vu19Yw7Ltp3kFl4hIC1NYNCa6M9zyKnRJh7k3wMHNQdt1fEwkc741hv5JnblzTjYr1H8hIm2AwuKrxCXCzNchIgZeuA7KcoO2626xUbzw7TH06h7Lt/66itV7S4O2bxGRUFBYnEz3TLj1Nag6Cs9/AyqC96Xeo3M0L945ltQuMdz+7CrW5x4O2r5FRIJNYdGU1OFw01w4tBvm3gjVFUHbdXJ8DC/eOZZucZHMfOZTcg5oClYRaZ0UFs3R9wK47mnIXeXv9K4L3pAdaV07MfeO84mLCufWZ1ayvfBo0PYtIhIsCovmGjINrvgtbHsP3v5BUO/y7pUQy4t3nk9EmDHj6ZXsKjoWtH2LiASDwuJUnHcHXPhv/lFqP3gkqLvumxjH3DvH4vM5Zjy1kn0lwTvdJSJyphQWp2riz2DULFj2O1j5l6DuekByPC/cMZbK2jpmPL2CvMPHg7p/EZHTpbA4VWZwxaNw1hX+QQc3vhbU3Z+d1oXnvzWWsuM13PLUCgqPVAZ1/yIip0NhcTrCI2D6M9D7fHj9O7BrSVB3PzyjK7O/NYaio1XMeGoFxcdCM8+GiEhzKSxOV2QnuPlvkDgQXroV8tcFdfejenfnuW+O4cDhSm59eiWHyquDun8RkVOhsDgTnbr7b9rr1A1emA6lu4K6+zF9E3h6Vha7isuZ+exKyo7XBHX/IiLNpbA4U116wq2vg6/Gf5f3sYNB3f2EAYn8ZeZothYcZdazn3JM07KKiAcUFsGQNAhmvApHC+DF6f7hQYJo4lnJPD5jFBvzyvjWc6uoqFZgiEjLUlgES6/z4IbZULARXr4VaoPbxzBpaCqP3XQu2XtLuWN2NpU1oZkrXESkMQqLYBo0Ga7+g//qqDfv9s+8F0RXntOT390wguW7Srj7hdVU1SowRKRlKCyCbeQtcNlD/vsvFv4sqMOCAFw7MoNfXTucJVuLuHfuZ9TUBTeQREQao7AIhQn3w9jvwson4J+PBX33N43pzcPThrI4p5D7X1pLrQJDREIswusC2iUzmPxLKC+CfzwEccn+I44gum1cJtW1Pv5jwWaiIsL47fUjCA+zoL6HiMgJCotQCQuDa56AimJ46/v+mfcGTQ7qW9xxQT+qan38ZuFWoiPC+OW1wwlTYIhICOg0VChFRMGNL/gnUHplFuxfFfS3uGfiAO67ZAAvrdrPQ/M34YLcRyIiAgqL0IuOh1vmQXwqzL0eirYG/S1+ePkgvnNhP+Ys38t/LtiswBCRoFNYtITOSTDzdQiL9N/lXZYX1N2bGQ9MHczt4zN5+uPd/G7RtqDuX0TE2stfoVlZWS47O9vrMk4ufx08dwXEdIGEfkHfvcOxq6icg0eq6JXQiYzusf4XUs+BC38MsQlBf08RadvMbLVzLqupdjqyaElpI2DGy9BjADhf0B/mHP16dCI5PpK8Q+UcOFQOdTX+S3j/MBpWPQM+3cgnIqeuWUcWZvYD4DngKPA0MBJ4wDm3KLTlNV+bOLJoIXU+x/0vr2X+ugM8dNUQbu9fDu89AHuWQcpw+Pp/Q5/xXpcpIq1AsI8svuWcOwJMAroDM4Ffn0F9EkLhYcajN4xg8tAUHpqfwzM74nC3vQXXz4bKw/DcVJj3LSjL9bpUEWkjmhsWJy7e/zrwvHNuU7110gpFhofxh5tHcdnZKTzydg53zFlNUe+pcM+ncNEDsGUB/PE8+Og3UKOpW0Xk5JobFqvNbBH+sFhoZvGAxpho5aIiwnhy5mj+35VDWLajmMmPfcR7247AxAf9oTHgMvjgP+DxMbD57aCPYyUi7Udz+yzCgHOBXc65w2aWAGQ459aHusDmUp/FyW0vPMoPX1nLxrwjTB+dwS+uGkJ8TCTsWgrv/hSKNkO/iTD1vyDpLK/LFZEWEuw+i3HA1kBQ3Ar8O1B2JgVKyxqYEs/r353AvRMH8PqaXKY8towVu0qg30Vw98cw9TdwYA08MR7eexCOH/a6ZBFpRZobFk8AFWY2AvgRsBOYE7KqJCSiIsL48eSzePXu8USGGzc/tYJfvrOZSp/B2Lvg+5/ByJmwInCp7Zo5QZ+TQ0TapuaGRa3zn6+aBvzROfc4EN/URmY2xcy2mtkOM3ugkddvN7MiM1sbeNxR77VZZrY98JjV3A8kTRvdpzsL7ruAm8f05smPdjHtj/8k58ARiOsBVz0G31kKiQP9AyA+NRH2rfS6ZBHxWHPD4qiZPYj/ktkFgT6MyJNtYGbhwOPAVGAIcLOZDWmk6cvOuXMDj6cD2yYAvwDGAmOAX5hZ92bWKs0QFx3BL68dznO3n0dpRTXTHv+YJ5bspM7n/DcPfvNduO4ZOHYQnp0Er38HjuR7XbaIeKS5YXEjUIX/fosCIAP4TRPbjAF2OOd2OeeqgZfwH5k0x2RgsXOu1Dl3CFgMTGnmtnIKJg5OZuH9F3LZ2Sn813tbuOnJ5ewrqfDPyTF8Oty7Ci74MWx6Hf6YBR//D9RWeV22iLSwZoVFICBeBLqa2ZVApXOuqT6LdGB/veXcwLqGrjOz9WY2z8x6neK2EgQJcVH86ZZRPHrDCLbkH2Xq7z/i5VX7/KPXRneGS38O96yEvhf5J3P60/mwbaHXZYtIC2pWWJjZDcCnwPXADcBKM5sehPefD2Q6587Bf/Qw+1Q2NrO7zCzbzLKLioqCUE7HZWZ8Y1QG7/3wQoZndOWnr23gzjnZFB0NHEUk9IOb58Ktr0NYBMy9AV6YDsXbvS1cRFpEc09D/V/gPOfcLOfcbfhPMf28iW3ygF71ljMC6z7nnCtxzp04p/E0MLq52wa2f9I5l+Wcy0pKSmrmR5GTSe/Wibl3nM+/X3E2H20vZspjH7FoU8G/Ggy4FL77iX/a2P0r4U/jYNHPofKId0WLSMg1NyzCnHMH6y2XNGPbVcBAM+trZlHATcBb9RuYWVq9xauBzYHnC4FJZtY90LE9KbBOWkBYmHHHBf14+/tfI6VLDHc9v5p/m7eOo5U1/gbhkTDuHvj+ahhxE3zyB39/xtq5utRWpJ1qbli8Z2YLA5e63g4sAN452QbOuVrgXvxf8puBV5xzm8zsYTO7OtDsPjPbZGbrgPuA2wPblgKP4A+cVcDDgXXSggalxPPmPRO4Z2J/5q3OZervl/Hp7nq/hs7JMO2PcOf70K03vPldeOZyyH4WCjZAXa13xYtIUDV78iMzuw6YEFhc5px7I2RVnQYN9xFaq/eW8sOX17H/UAV3XdiP/3P5IKIjwv/VwOeD9S/7x5o6EhjNNjIO0kdBxnmBR5Y/YESk1WjucB+aKU+arbyqlv9YkMPfPt3P4NR4/ufGczk7rcsXGzkHh/ZAbjbkrvI/CtaDL3CU0a1PvfA4D1KHQ0RUi38WEfELSliY2VGgsQYGOOdcl0Ze84TCouW8v7mQn762gSPHa/jRpEHccUE/wsNOMmJ9zXH/lLInwiM3G44ErlcIj/bfBJhxHvQKBEiXdP99HiIScjqykJAqOVbFz97YwMJNhYzJTOB3N4ygV0Js83dQlgd5gaOP/asgfy3UBubViE/zn7I6cfSRdi5EncK+RaTZFBYScs45XluTx0NvbQLg/101hOtHZ2Cnc1RQWw2FG794+urQbv9rFg6pw754+iqhn44+OrKaSqg64r9ku7IMqsrqPQ+srwosn3j+pfnnG3z3Nfpd2Mi6L7VrpI2FQ2xC4JEIsT38j7gTzwPro+M9/3essJAWs7+0gh+/uo6Vu0u5fEgK/3ntMJLjY858x+XFgfD41B8eeWug+pj/tU4J/tBIGQrhzejzaNZ/yGa0CQuDiBj/6bOIqAY/YxpZF+2v7wuvRXv+BeEJ56Cuxn8EWVvp/1029qXeMAC+9HoZ1FU38WYG0V0gpgvEdPV/KYdFNNKs4e+hkd9Lo78rO3mbuhr/MP8Vxf5/x76axssMi6wXIgmBIEn86nWxPYLex6ewkBbl8zme+Xg3v1m4laiIMH5w6UBmjc8kKqK5V2c3503qoGjLF/s+irbSeLdaKxcW6Q+NiOivCJ7AIyzSf19LWIT/ceJ5eGQzXwv/YruvfC3S/4VXV+3vY6qtgtrAz8+XK//1qKn84vIX2p1kO9fM+3Ai4+p90Qe+9KMDy1943rWR9V0gKt4f7K2Bc1B1FCpKoKLUHyAVJf5HefGX15cXQ+VJ5pOJ7vLlEEk+Gybcd1rlKSzEE7uLy3l4/iY+3FpEv6Q4HrpqKBcO8vju+ub8G2/u/wNfjf8LsK468LPKfwqtrirwxdhwXbX/S7LR9idea7Cu/r58Nf77VXw1/ivKTjyvq/nya839Ij5Tnx8pRUNEJ//PyJjAuph/vRbZ6YttImK+2C4qrsFf//V+hjdyFNCR1NXC8UONBEtpYLn4i+uSBsHM07ubQWEhnvpgSyEPz89hT0kFlw9J4edXDKF3D3VSh5TP10iQ1A+X2n+95qur165e2Jz4Uj/xaCwEwsKbrkXaDIWFeK6qto5nPt7NHz/YQa3P8Z0L+/Hdi/sTG9XB/2oUaUWCPQe3yCmLjgjnexcP4IMfXczUYan84YMdXPa7pby9/gDt5Y8UkY5CYSEhl9o1ht/fNJJX7x5Ht9go7p37GTc/tYItBRqpVqStUFhIizkvM4H53/8a/3HNMLYUHOXrv1/GL/6+kcMVTV0GKSJeU1hIiwoPM249vw9Lfnwxt4ztw/Mr9jLxt0uYu3Kff/5vEWmVFBbiiW6xUTxyzTDe/v4FDEyO52dvbGDa4x+zeq9GohdpjRQW4qkhPbvw8nfO539vHknx0Wque2I5P3x5LYVHKr0uTUTqUViI58yMq0f05P0fXcQ9E/uzYH0+l/x2CX9eupOq2obj+YiIFxQW0mrERUfwk8mDWfx/LmRc/x78+t0tTHlsGR9uPdj0xiISUgoLaXX69Ijj6Vnn8dw3z8OAbz63im//dRV7isu9Lk2kw1JYSKs18axk3rv/Qh6YOpgVu0qY9D8f8d/vbaG8SnN7i7Q0hYW0alERYdx9UX8++PHFXHlOGn9aspNLf7eUv6/N013gIi1IYSFtQkqXGB698Vzm3T2OxPgofvDSWm74y3I2HSjzujSRDkFhIW1KVmYCf7/na/zy2uHsOHiMK//wMXc/v5r1uScZ/19EzpiG/5Q2JzzMmDG2N1cMT+OpZbuYvXwP720q4IKBidwzcQBj+yac3tSuIvKVNES5tHlHKmt4YcVenv14N8XHqhndpzv3TOzPxLOSFRoiTdB8FtLhVNbU8Ur2fv6ydBd5h48zODWe700cwBXD0wgPU2iINEZhIR1WTZ2Pv689wBNLdrCzqJzMHrHcfVF/rh2VTnSEZnkTqU9hIR2ez+dYlFPA4x/uZENeGaldYrjzwn7cPKaXZusTCVBYiAQ451i2vZjHP9zByt2ldI+N5FsT+nLbuEy6xkZ6XZ6IpxQWIo1YvbeUP324k/e3HKRzdAS3nN+bb3+tL8nxMV6XJuIJhYXISeQcOMITS3eyYP0BIsLDuDGrF3dd2I9eCbFelybSohQWIs2wu7icvyzdyWtrcvE5mHZuT753cX8GJMd7XZpIi1BYiJyC/LLjPL1sN3NX7qOyto7JQ1L53sT+nJPRzevSREJKYSFyGkrLq/nrP3fz10/2cKSyVneFS7unsBA5A0cra3hx5T6eXrab4mNVjOrdjXsmDuCSwborXNqX5oZFSAcSNLMpZrbVzHaY2QMnaXedmTkzywosZ5rZcTNbG3j8OZR1ijQUHxPJ3Rf15+OfTuSRa4Zx8GgV356dzWWPLuXPS3dyUHOESwcTsiMLMwsHtgGXA7nAKuBm51xOg3bxwAIgCrjXOZdtZpnA2865Yc19Px1ZSCjV1Pl4e/0B5q7cx6o9hwgPMy4alMT00Rlcenay7gyXNqu5RxahvI11DLDDObcrUNBLwDQgp0G7R4D/An4SwlpEzkhkeBjXjszg2pEZ7C4uZ97q/by2Oo/vbVlD99hIpp2bzvTRGQxL7+p1qSIhEcrTUOnA/nrLuYF1nzOzUUAv59yCRrbva2afmdlSM7sghHWKnJK+iXH8ZPJg/vnAJfz1m+cxYUAicz/dx5V/+Jipv1/Gsx/vprS82usyRYLKswFyzCwMeBS4vZGX84HezrkSMxsNvGlmQ51zRxrs4y7gLoDevXuHuGKRLwoPMy4+K5mLz0rmcEU189cd4NXVuTz8dg6/enczlw5O4fqsDC4alEREuOYZk7YtlH0W44CHnHOTA8sPAjjnfhVY7grsBI4FNkkFSoGrnXPZDfa1BPhxw/X1qc9CWostBUeYl53LG5/lUVJeTVJ8NN8Ymc71WRm62U9aHc8vnTWzCPwd3JcCefg7uGc45zZ9RfslBALBzJKAUudcnZn1A5YBw51zpV/1fgoLaW1q6nx8uOUgr67O5cMtB6n1OUb06sb1ozO4akRPunbSIIbiPc87uJ1ztWZ2L7AQCAeedc5tMrOHgWzn3Fsn2fxC4GEzqwF8wN0nCwqR1igyPIxJQ1OZNDSV4mNVvPlZHq9m5/Lvb27kkbdzmDw0leuzMpjQP5EwTc4krZxuyhNpQc45NuSV8Wp2Ln9fm8eRylp6do3hutEZTB+dQZ8ecV6XKB2M56ehWprCQtqaypo6FucU8urqXJZtL8I5GNM3getHZ/D14WnERWuCJgk9hYVIG5JfdpzX1+TxavZ+9pRUEBsVzhXD05g+OoMxGpdKQkhhIdIGOefI3nuIV7P3s2B9PuXVdfROiGX66Ay+MSqdjO6ab0OCS2Eh0sZVVNfy3sYC5q3O5ZOdJQCM79+D6aMzmDIsVfOIS1AoLETakf2lFby+Jo95a/azv/Q4cVHhXHFOGtdn9SKrT3edppLTprAQaYd8PseqPaXMW53Lgg35VFTX0adHLNNHZfCN0Rmkd+vkdYnSxigsRNq58qp/naZavqsEs3qnqYam0SlKI+FK0xQWIh1Iw9NUnaMjuGJ4GtdnZTBap6nkJBQWIh2Qz+f4NHCa6p3AaarMHv6rqa4dpdNU8mUKC5EOrryqlnc3FjBv9X5W7CrFDCb0T2T66AwmD03VaSoBFBYiUs/+0gpeW5PLvNW55B46Tnx0BFeO8N/0N6q3TlN1ZAoLEfmSxk5T9U2M85+mGplOT52m6nAUFiJyUuVVtbyzIZ95q3NZudt/muq8zASuOieNqcPTSOwc7XWJ0gIUFiLSbPtKKnhzbR7z1x1g+8FjhBmM75/IVSPSmDw0lW6xUV6XKCGisBCR07K14Cjz1x3g7fUH2FNSQWS4ccHAJK4akcblQ1LprNFw2xWFhYicEeccG/OOMH/9Ad5ed4ADZZVER4RxyeBkrjynJ5cMTtYVVe2AwkJEgsbnc3y2/xDz1+WzYEM+RUeriI0K5/IhKVx5Tk8uHJRIdISCoy1SWIhISNT5HCt3lzB/XT7vbszncEUN8TERTBmaypUjejK+fw8iw8O8LlOaSWEhIiFXU+fjnzuKmb8un0WbCjhaVUtCXBRThqVy1Tk9GdM3gXDNL96qKSxEpEVV1tTx0bYi5q/P5x85hRyvqSM5PpqvD0/jqhE9GdW7m27+a4UUFiLimYrqWj7YcpD56w7w4dYiqmt9pHfrxJXn+INjaM8uCo5WQmEhIq3C0coaFucUMn/dAZZtL6bW5+ibGMcVw9OYOjyVIWkKDi8pLESk1TlUXs3CTQXMX3+A5TtL8DnonRDL1GGpTB2exoiMrgqOFqawEJFWreRYFYtzCnlnYwFvu+QHAAAKpElEQVSf7PAfcfTsGsOUYf4jjtG9uxOmzvGQU1iISJtRVlHDPzYX8u7GfD7aXkx1rY/k+GgmD01l6rBUxvRNIEKX44aEwkJE2qRjVf7O8Xc35PPh1oNU1vhIiIti0pAUpg5PY1y/HkRFKDiCRWEhIm1eRXUtS7cW8e7GAt7fXEh5dR1dYiK4bEgKXx+WxtcGJhITqTvHz4TCQkTalcqaOj7eXsy7GwtYnFPAkcpa4qLCueTsFL4+LJWLzkoiNkqDHJ4qhYWItFvVtT6W7yrh3Q35LMoppLS8mpjIMCaelcyUYalcMjiZ+JhIr8tsExQWItIh1Nb5+HR3Ke9uLOC9TQUUHa0iKiKMCwcmMmVYGpefnULXWAXHV1FYiEiH4/M5Vu87xLsbCnhvYz4HyiqJCDPGD0hk8tAULj87heQuMV6X2aooLESkQ3POsS63jHc35vPuhgL2lVYAMLJ3NyYNSWXS0BT6J3X2uErvKSxERAKcc2wrPMaiTQUsyilkQ14ZAP2S4j4PjnMzunXImwAVFiIiX+HA4eP8Y3MhizYVsmJXCbU+R1J8NJcPSeHyISmM79+jw0zm1CrCwsymAL8HwoGnnXO//op21wHzgPOcc9mBdQ8C3wbqgPuccwtP9l4KCxE5HWUVNXy49SCLcwpZsvUg5dV1dI6O4KKzkpg0JIWLz0qma6f220He3LAI2UXJZhYOPA5cDuQCq8zsLedcToN28cAPgJX11g0BbgKGAj2Bf5jZIOdcXajqFZGOqWtsJNeMTOeakelU1tSxfGcJi3IKWZxTyIL1+USEGeP692DSkBQuG5JCWtdOXpfsiZAdWZjZOOAh59zkwPKDAM65XzVo9xiwGPgJ8GPnXHbDtma2MLCv5V/1fjqyEJFg8s87fphFOQUs3lTIruJyAM7J6MqkISlMGprKwOTObX6UXM+PLIB0YH+95VxgbP0GZjYK6OWcW2BmP2mw7YoG26aHqlARkYbCwozRfbozuk93Hpx6NjsOHmNRTgGLNhXy20Xb+O2ibWT2iOXyQHCM6t29XU8h69m98WYWBjwK3H4G+7gLuAugd+/ewSlMRKQRA5I7MyB5AN+7eACFRyo/7yCf/clenlq2mx5xUVx2tr+DvD2OWRXKsMgDetVbzgisOyEeGAYsCRzGpQJvmdnVzdgWAOfck8CT4D8NFcziRUS+SkqXGG4Z24dbxvbhaGUNS7cVsWhTIe9syOfl7P3ERIZxXmYC4/snMr5/D4ald23zRx2h7LOIALYBl+L/ol8FzHDObfqK9kv4V5/FUGAuMAZ/B/f7wMCTdXCrz0JEvFZd62Pl7hLe33yQ5TtL2Fp4FID4mAjG9u3BhAE9GN8/kUEpraevw/M+C+dcrZndCyzEf+nss865TWb2MJDtnHvrJNtuMrNXgBygFrhHV0KJSGsXFRHGBQOTuGBgEgBFR6tYsauET3YW88nOEv6xuRCAxM5RnN+vBxMG+I88eifEtprw+Cq6KU9EpIXkHqpg+c4SPtnpD5DCI1UApHfrxLj+PRjf33/kkdq15cavahU35bUkhYWItCXOOXYVl/PJDv9Rx/JdJRyuqAH8w5CM79+DCf0TOb9fD7rHRYWsDoWFiEgb4vM5Nhcc4ZMd/qOOT3eXUl5dhxmcndrFHx4DEjmvbwKdo4PXg6CwEBFpw2rqfKzPLfv8yGP1vkNU1/oIDzNGZHT9/EqrUX26n9FlugoLEZF2pLKmjjV7D/HPQGf5+twy6nyOqIgwJg1J4Y8zRp3Wfj2/GkpERIInJjKc8QMSGT8gEYCjlTWs2lPKP3eUEB0RFvL3V1iIiLRB8TGRXDI4hUsGp7TI+4U+jkREpM1TWIiISJMUFiIi0iSFhYiINElhISIiTVJYiIhIkxQWIiLSJIWFiIg0qd0M92FmRcDeM9hFIlAcpHJaG322tqs9fz59ttahj3MuqalG7SYszpSZZTdnfJS2SJ+t7WrPn0+frW3RaSgREWmSwkJERJqksPiXJ70uIIT02dqu9vz59NnaEPVZiIhIk3RkISIiTerwYWFmU8xsq5ntMLMHvK4nmMysl5l9aGY5ZrbJzH7gdU3BZmbhZvaZmb3tdS3BZGbdzGyemW0xs81mNs7rmoLJzH4Y+De50cz+ZmYxXtd0uszsWTM7aGYb661LMLPFZrY98LO7lzUGQ4cOCzMLBx4HpgJDgJvNbIi3VQVVLfAj59wQ4Hzgnnb2+QB+AGz2uogQ+D3wnnNuMDCCdvQZzSwduA/Ics4NA8KBm7yt6oz8FZjSYN0DwPvOuYHA+4HlNq1DhwUwBtjhnNvlnKsGXgKmeVxT0Djn8p1zawLPj+L/wkn3tqrgMbMM4Argaa9rCSYz6wpcCDwD4Jyrds4d9raqoIsAOplZBBALHPC4ntPmnPsIKG2wehowO/B8NnBNixYVAh09LNKB/fWWc2lHX6b1mVkmMBJY6W0lQfUY8G+Az+tCgqwvUAQ8FzjF9rSZxXldVLA45/KA3wL7gHygzDm3yNuqgi7FOZcfeF4AtMzcpyHU0cOiQzCzzsBrwP3OuSNe1xMMZnYlcNA5t9rrWkIgAhgFPOGcGwmU0w5OY5wQOH8/DX8o9gTizOxWb6sKHee/5LTNX3ba0cMiD+hVbzkjsK7dMLNI/EHxonPuda/rCaIJwNVmtgf/6cNLzOwFb0sKmlwg1zl34ihwHv7waC8uA3Y754qcczXA68B4j2sKtkIzSwMI/DzocT1nrKOHxSpgoJn1NbMo/J1sb3lcU9CYmeE/773ZOfeo1/UEk3PuQedchnMuE//v7QPnXLv469Q5VwDsN7OzAqsuBXI8LCnY9gHnm1ls4N/opbSjDvyAt4BZgeezgL97WEtQRHhdgJecc7Vmdi+wEP8VGc865zZ5XFYwTQBmAhvMbG1g3c+cc+94WJM0z/eBFwN/xOwCvulxPUHjnFtpZvOANfiv2PuMNnzHs5n9DbgYSDSzXOAXwK+BV8zs2/hHw77BuwqDQ3dwi4hIkzr6aSgREWkGhYWIiDRJYSEiIk1SWIiISJMUFiIi0iSFhUgrYGYXt7eRc6V9UViIiEiTFBYip8DMbjWzT81srZn9JTCfxjEz+5/A/Azvm1lSoO25ZrbCzNab2Rsn5jQwswFm9g8zW2dma8ysf2D3nevNYfFi4O5mkVZBYSHSTGZ2NnAjMME5dy5QB9wCxAHZzrmhwFL8d/ACzAF+6pw7B9hQb/2LwOPOuRH4x0Q6MTrpSOB+/HOr9MN/B75Iq9Chh/sQOUWXAqOBVYE/+jvhHyDOB7wcaPMC8HpgTopuzrmlgfWzgVfNLB5Id869AeCcqwQI7O9T51xuYHktkAl8HPqPJdI0hYVI8xkw2zn34BdWmv28QbvTHUOnqt7zOvT/U1oRnYYSab73gelmlgyfz7PcB///o+mBNjOAj51zZcAhM7sgsH4msDQwY2GumV0T2Ee0mcW26KcQOQ36y0WkmZxzOWb278AiMwsDaoB78E9ONCbw2kH8/RrgH5r6z4EwqD9y7EzgL2b2cGAf17fgxxA5LRp1VuQMmdkx51xnr+sQCSWdhhIRkSbpyEJERJqkIwsREWmSwkJERJqksBARkSYpLEREpEkKCxERaZLCQkREmvT/ASncYJCWjlLLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(LSTM_model.history['loss'],label='train')\n",
    "plt.plot(LSTM_model.history['val_loss'],label='validation')\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7949163050216987,\n",
       " 0.806478611283323,\n",
       " 0.8036887786732796,\n",
       " 0.8123992560446374,\n",
       " 0.8144141351518909,\n",
       " 0.8172659640421575,\n",
       " 0.8170799752014879,\n",
       " 0.8185368877867328,\n",
       " 0.8218226906385617,\n",
       " 0.8210787352758835,\n",
       " 0.8225356478611283,\n",
       " 0.8233725976441414]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8470000097751618,\n",
       " 0.8522500097751617,\n",
       " 0.8575416767597198,\n",
       " 0.8592500100135804,\n",
       " 0.8623750069141388,\n",
       " 0.8616666796207428,\n",
       " 0.861833342552185,\n",
       " 0.86329167842865]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## first try\n",
    "## 1000\n",
    "[0.7633334,\n",
    " 0.765,\n",
    " 0.7733334,\n",
    " 0.7766667,\n",
    " 0.79,\n",
    " 0.78333336,\n",
    " 0.77833337,\n",
    " 0.77833337,\n",
    " 0.78666663]\n",
    "\n",
    "## 10000\n",
    "[0.7896667,\n",
    " 0.78500015,\n",
    " 0.79650015,\n",
    " 0.7953333,\n",
    " 0.7994998,\n",
    " 0.79933333,\n",
    " 0.79466665,\n",
    " 0.79899997,\n",
    " 0.79566664,\n",
    " 0.7911668,\n",
    " 0.8008332,\n",
    " 0.8033334,\n",
    " 0.7893331,\n",
    " 0.8063332,\n",
    " 0.80533326,\n",
    " 0.8041667]\n",
    "\n",
    "## 20000\n",
    "[0.8406666798591613,\n",
    " 0.8463333468437195,\n",
    " 0.8442500100135804,\n",
    " 0.8465000066757202,\n",
    " 0.845666675567627,\n",
    " 0.8399166750907898]\n",
    "\n",
    "## 40000\n",
    "[0.846000010728836,\n",
    " 0.8528333415985108,\n",
    " 0.8522500121593475,\n",
    " 0.8555416769981384,\n",
    " 0.829625009059906,\n",
    " 0.8536250035762787,\n",
    " 0.8491666755676269]\n",
    "\n",
    "## all\n",
    "[0.8746228654859085,\n",
    " 0.8851105690445873,\n",
    " 0.889078329655966,\n",
    " 0.8945443354995075,\n",
    " 0.896011581290825,\n",
    " 0.8991320621279996,\n",
    " 0.8992973819550564,\n",
    " 0.9017668994849171,\n",
    " 0.9046290611673865,\n",
    " 0.908173181695814]\n",
    "\n",
    "\n",
    "## add convential layer and dropout(0.2)\n",
    "## 20000\n",
    "[0.8463333458900452,\n",
    " 0.8495833463668824,\n",
    " 0.8557500090599061,\n",
    " 0.8566666769981385,\n",
    " 0.858500009059906,\n",
    " 0.8403333406448364,\n",
    " 0.8505833492279052,\n",
    " 0.8565000033378601]\n",
    "\n",
    "## 40000\n",
    "[0.8470000097751618,\n",
    " 0.8522500097751617,\n",
    " 0.8575416767597198,\n",
    " 0.8592500100135804,\n",
    " 0.8623750069141388,\n",
    " 0.8616666796207428,\n",
    " 0.861833342552185,\n",
    " 0.86329167842865]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53766/53766 [==============================] - 67s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49736629969523927, 0.8178774667864633]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accr = model.evaluate(X_test,y_test, batch_size = 100)\n",
    "accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2909027664530948, 0.8856464531903855]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 10000\n",
    "## [0.4519780118446444, 0.8386464840319391]\n",
    "\n",
    "## 40000\n",
    "[0.3983093709805641, 0.8546789216107478]\n",
    "\n",
    "## all with only conv\n",
    "[0.2909027664530948, 0.8856464531903855]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163740</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206473</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159672</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39293</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97768</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208087</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215892</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169852</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23295</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71428</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196802</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66736</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97013</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213376</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151674</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33173</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30401</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152490</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231397</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38116</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102969</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12626</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190527</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173391</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35608</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187230</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211675</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176383</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222080</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8173</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221708</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131040</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23352</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208660</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77300</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182207</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110775</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199982</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127066</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153929</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151266</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212844</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76895</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194823</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193118</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35261</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139347</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123432</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140714</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130945</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47656</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113712</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53766 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        high  low  medium\n",
       "163740     1    0       0\n",
       "206473     1    0       0\n",
       "159672     1    0       0\n",
       "39293      1    0       0\n",
       "97768      1    0       0\n",
       "208087     0    1       0\n",
       "215892     0    0       1\n",
       "169852     1    0       0\n",
       "23295      1    0       0\n",
       "71428      0    1       0\n",
       "196802     0    1       0\n",
       "31947      0    0       1\n",
       "4907       0    1       0\n",
       "66736      1    0       0\n",
       "97013      0    1       0\n",
       "213376     1    0       0\n",
       "151674     1    0       0\n",
       "33173      0    1       0\n",
       "30401      0    0       1\n",
       "152490     1    0       0\n",
       "231397     0    1       0\n",
       "38116      1    0       0\n",
       "102969     0    1       0\n",
       "12626      0    1       0\n",
       "190527     1    0       0\n",
       "229975     0    0       1\n",
       "173391     1    0       0\n",
       "35608      1    0       0\n",
       "187230     1    0       0\n",
       "211675     1    0       0\n",
       "...      ...  ...     ...\n",
       "176383     1    0       0\n",
       "123174     0    0       1\n",
       "222080     0    1       0\n",
       "8173       1    0       0\n",
       "221708     1    0       0\n",
       "131040     0    1       0\n",
       "23352      1    0       0\n",
       "208660     1    0       0\n",
       "77300      1    0       0\n",
       "182207     1    0       0\n",
       "110775     1    0       0\n",
       "199982     0    1       0\n",
       "127066     1    0       0\n",
       "153929     1    0       0\n",
       "4705       0    1       0\n",
       "151266     0    1       0\n",
       "212844     1    0       0\n",
       "204390     1    0       0\n",
       "76895      0    1       0\n",
       "194823     1    0       0\n",
       "193118     1    0       0\n",
       "35261      1    0       0\n",
       "139347     0    1       0\n",
       "33495      0    0       1\n",
       "123432     1    0       0\n",
       "159999     1    0       0\n",
       "140714     1    0       0\n",
       "130945     1    0       0\n",
       "47656      0    1       0\n",
       "113712     1    0       0\n",
       "\n",
       "[53766 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test#.values#.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817877469032474"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.values.argmax(axis=1),y_test_pred)\n",
    "## 10000\n",
    "## 0.7498047092958375\n",
    "\n",
    "## 40000\n",
    "## 0.7756574787040137\n",
    "\n",
    "## second try\n",
    "## 40000\n",
    "## 0.7865007625637019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33203,  1766,   471],\n",
       "       [ 2816, 10223,   458],\n",
       "       [ 2649,  1632,   548]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.values.argmax(axis=1),y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high      35440\n",
       "low       13497\n",
       "medium     4829\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8227690361938772"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(32352+10904+981)/53766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_amazonei_tensorflow_p36)",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
